{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meu primeiro Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam sed orci dapibus odio aliquam tempus et a lacus. Donec laoreet orci felis, eget consequat elit cursus aliquet. Fusce facilisis, nisl et venenatis ultrices, orci velit dictum nibh, et hendrerit risus metus nec felis. Proin a pretium nisl. Maecenas placerat convallis mi ut vehicula. Ut eget faucibus ante, vel feugiat orci. Nam eget neque nec nunc congue placerat. Maecenas sed cursus massa. Mauris porttitor nisl ut placerat dignissim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requeriments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request as urllib_request\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS4 version: 4.10.0\n",
      "URLLIB version: 3.9\n",
      "PANDAS version: 1.3.5\n"
     ]
    }
   ],
   "source": [
    "print(\"BS4 version: \" + bs4.__version__)\n",
    "print(\"URLLIB version: \" + urllib_request.__version__)\n",
    "print(\"PANDAS version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://alura-site-scraping.herokuapp.com/hello-world.php'\n",
    "\n",
    "response = urlopen(url)\n",
    "html = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!!!\n",
      "Web Scraping é o termo utilizado para definir a prática de coletar automaticamente informações na Internet. Isto é feito, geralmente, por meio de programas que simulam a navegação humana na Web.\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.find('h1', id='hello-world').get_text())\n",
    "print(soup.find('p').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Curso de Web Scraping'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1', {'class': 'sub-header'}).get_text()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3fd963aa9ad58e2531582e8e0a8773180383fbcc3ff5f2a982bb86ede546f31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
